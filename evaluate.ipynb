{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jh2UzyIdYoYb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "label_cols = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/toxic_data/test.csv\")\n",
        "df_test_labels = pd.read_csv(\"/content/drive/MyDrive/toxic_data/test_labels.csv\")\n",
        "\n",
        "df_test = pd.merge(df_test, df_test_labels, on=\"id\")\n",
        "df_test = df_test[df_test[label_cols].ne(-1).all(axis=1)]\n",
        "df_test[\"label\"] = (df_test[label_cols].sum(axis=1) > 0).astype(int)\n",
        "\n",
        "texts = df_test[\"comment_text\"].astype(str).tolist()\n",
        "labels = df_test[\"label\"].values"
      ],
      "metadata": {
        "id": "gXiw67J6Y9I0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model.to(\"cuda\")\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "dnsx90SDR-gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "\n",
        "encodings = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "dataset = TensorDataset(\n",
        "    encodings[\"input_ids\"],\n",
        "    encodings[\"attention_mask\"],\n",
        "    torch.tensor(labels)\n",
        ")\n",
        "loader = DataLoader(dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "Ev_ZiPHHSCwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        input_ids, attention_mask, _ = [b.to(\"cuda\") for b in batch]\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds.extend(torch.argmax(logits, dim=1).cpu().numpy())"
      ],
      "metadata": {
        "id": "gneQcVcRSF1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, preds))\n",
        "print(\"F1 (toxic):\", f1_score(labels, preds))  # binary = class 1\n",
        "print(classification_report(labels, preds))"
      ],
      "metadata": {
        "id": "rV8wuTT8SUMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import AutoPeftModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = AutoPeftModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/models/lora-toxic-roberta\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/models/lora-toxic-roberta\")\n",
        "\n",
        "model.eval().to(\"cuda\")"
      ],
      "metadata": {
        "id": "xv29QWGIfJta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "encodings = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "dataset = TensorDataset(\n",
        "    encodings[\"input_ids\"],\n",
        "    encodings[\"attention_mask\"],\n",
        "    torch.tensor(labels)\n",
        ")\n",
        "loader = DataLoader(dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "Y80acfF4ZIVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        input_ids, attention_mask, _ = [b.to(\"cuda\") for b in batch]\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds.extend(torch.argmax(logits, dim=1).cpu().numpy())"
      ],
      "metadata": {
        "id": "RR0KH5CLZfAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, preds))\n",
        "print(\"F1 Score:\", f1_score(labels, preds))\n",
        "print(classification_report(labels, preds))"
      ],
      "metadata": {
        "id": "Bq5UppxoZf6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_probs = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        input_ids, attention_mask, label = [b.to(\"cuda\") for b in batch]\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=1)[:, 1]\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "        all_labels.extend(label.cpu().numpy())"
      ],
      "metadata": {
        "id": "JTj5Ckb8iFGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "print(\"F1 scores at different thresholds:\")\n",
        "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "for t in thresholds:\n",
        "    preds = (np.array(all_probs) > t).astype(int)\n",
        "    score = f1_score(all_labels, preds)\n",
        "    print(f\"Threshold: {t:.1f} â†’ F1 Score: {score:.4f}\")"
      ],
      "metadata": {
        "id": "DvOg_39riGWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, classification_report, precision_recall_curve\n",
        "\n",
        "prec, rec, thres = precision_recall_curve(all_labels, all_probs)\n",
        "f1s = 2 * (prec * rec) / (prec + rec + 1e-8)\n",
        "best_idx = f1s.argmax()\n",
        "best_threshold = thres[best_idx]\n",
        "best_f1 = f1s[best_idx]\n",
        "\n",
        "print(f\"Best Threshold: {best_threshold:.3f}\")\n",
        "print(f\"Best F1 Score: {best_f1:.4f}\")\n",
        "\n",
        "final_preds = (np.array(all_probs) > best_threshold).astype(int)\n",
        "print(\"\\nFinal classification report at best threshold:\")\n",
        "print(classification_report(all_labels, final_preds))"
      ],
      "metadata": {
        "id": "urlBXe6Blzsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "model_name = \"martin-ha/toxic-comment-model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "model.to(\"cuda\")\n",
        "model.eval()\n",
        "\n",
        "encodings = tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "dataset = TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"], torch.tensor(labels))\n",
        "loader = DataLoader(dataset, batch_size=32)\n",
        "\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for batch in loader:\n",
        "        input_ids, attention_mask, _ = [b.to(\"cuda\") for b in batch]\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(labels, preds))\n",
        "print(\"F1 Score:\", f1_score(labels, preds))\n",
        "print(classification_report(labels, preds))"
      ],
      "metadata": {
        "id": "TWGl7ZeNnSHC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}